{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b764f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import PyPDF2\n",
    "from docx import Document as DocxDocument\n",
    "\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain_core.output_parsers import PydanticOutputParser, StrOutputParser\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bfd6445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4110df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkSummary(BaseModel):\n",
    "    summary: str = Field(description=\"Brief summary of the chunk\")\n",
    "    key_topics: List[str] = Field(description=\"Key topics in this chunk\")\n",
    "    importance: str = Field(description=\"Importance level: high/medium/low\")\n",
    "\n",
    "class DocumentInfo(BaseModel):\n",
    "    title: str = Field(description=\"Inferred document title\")\n",
    "    document_type: str = Field(description=\"Type of document\")\n",
    "    estimated_pages: int = Field(description=\"total number of pages\")\n",
    "    language: str = Field(description=\"Primary language\")\n",
    "    subject_area: str = Field(description=\"Main subject domain\")\n",
    "\n",
    "class ContentAnalysis(BaseModel):\n",
    "    summary: str = Field(description=\"Comprehensive document summary\")\n",
    "    key_topics: List[str] = Field(description=\"Main topics covered\")\n",
    "    main_entities: List[str] = Field(description=\"Key entities mentioned\")\n",
    "    themes: List[str] = Field(description=\"Main themes\")\n",
    "\n",
    "class SemanticTags(BaseModel):\n",
    "    categories: List[str] = Field(description=\"Document categories\")\n",
    "    keywords: List[str] = Field(description=\"Important keywords\")\n",
    "    classification: List[str] = Field(description=\"Classification tags\")\n",
    "\n",
    "class FinalMetadata(BaseModel):\n",
    "    document_info: DocumentInfo\n",
    "    content_analysis: ContentAnalysis\n",
    "    semantic_tags: SemanticTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4632a46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_7648\\1810818240.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    }
   ],
   "source": [
    "llm = GoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\"),\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "chunk_parser = PydanticOutputParser(pydantic_object=ChunkSummary)\n",
    "metadata_parser = PydanticOutputParser(pydantic_object=FinalMetadata)\n",
    "str_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e998d483",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \" \"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db16cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_summary_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Analyze this document chunk and create a brief summary:\n",
    "\n",
    "    Chunk: {chunk_text}\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\",\n",
    "    input_variables=[\"chunk_text\"],\n",
    "    partial_variables={\"format_instructions\": chunk_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "final_metadata_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    Based on the most relevant document chunks, generate comprehensive metadata for document classification and discoverability:\n",
    "\n",
    "    Relevant Chunks:\n",
    "    {relevant_chunks}\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\",\n",
    "    input_variables=[\"relevant_chunks\"],\n",
    "    partial_variables={\"format_instructions\": metadata_parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2d337c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_chain = chunk_summary_prompt | llm | chunk_parser\n",
    "metadata_chain = final_metadata_prompt | llm | metadata_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17d69117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(uploaded_file):\n",
    "    \n",
    "    \n",
    "    if uploaded_file is None:\n",
    "        return \"Please upload a file\"\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Extract text from uploaded file\n",
    "        file_path = uploaded_file.name\n",
    "        ext = os.path.splitext(file_path)[1].lower()\n",
    "        \n",
    "        if ext == \".pdf\":\n",
    "            with open(file_path, 'rb') as file:\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                actual_pages = len(pdf_reader.pages)  # Get actual pages\n",
    "                text = \"\"\n",
    "                for page in pdf_reader.pages:\n",
    "                    text += page.extract_text() + \"\\n\"\n",
    "        elif ext == \".docx\":\n",
    "            doc = DocxDocument(file_path)\n",
    "            text = \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "            # Estimate pages for DOCX based on content length\n",
    "            total_chars = len(text)\n",
    "            actual_pages = max(1, round(total_chars / 2500))  # ~2500 chars per page\n",
    "        elif ext == \".txt\":\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                text = f.read().strip()\n",
    "            # Estimate pages for TXT based on content length\n",
    "            actual_pages = max(1, round(len(text) / 2500))  # ~2500 chars per page\n",
    "        elif ext in [\".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\"]:\n",
    "            image = cv2.imread(file_path)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            text = pytesseract.image_to_string(gray)\n",
    "            actual_pages = 1  # Images are always 1 page\n",
    "        else:\n",
    "            return \"Unsupported file type. Please upload PDF, DOCX, TXT, or image files.\"\n",
    "        \n",
    "        if len(text.strip()) < 100:\n",
    "            return \"Document appears to be empty or text extraction failed. Please try a different file.\"\n",
    "        \n",
    "        # Step 2: Chunk the text\n",
    "        chunks = text_splitter.split_text(text)\n",
    "        documents = [Document(page_content=chunk, metadata={\"chunk_id\": i}) for i, chunk in enumerate(chunks)]\n",
    "        \n",
    "        # # Step 3: Create embeddings locally using sentence transformers\n",
    "        # chunk_embeddings = embedding_model.encode([doc.page_content for doc in documents])\n",
    "        \n",
    "        # Step 4: Store in ChromaDB with local embeddings\n",
    "        persist_dir = \"./chroma_db_temp\"\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents=documents,\n",
    "            embedding=embedding_model,\n",
    "            persist_directory=persist_dir\n",
    "        )\n",
    "        vectorstore.persist()\n",
    "        \n",
    "        # Step 5: Retrieve most relevant chunks for metadata generation\n",
    "        overview_query = f\"main content summary key topics overview {text[:500]}\"\n",
    "        relevant_docs = vectorstore.similarity_search(overview_query, k=5)\n",
    "        \n",
    "        # Step 6: Generate chunk summaries using Gemini with Pydantic validation\n",
    "        chunk_summaries = []\n",
    "        for doc in relevant_docs:\n",
    "            try:\n",
    "                chunk_result = chunk_chain.invoke({\"chunk_text\": doc.page_content[:800]})\n",
    "                chunk_summaries.append(f\"Summary: {chunk_result.summary}, Topics: {', '.join(chunk_result.key_topics)}, Importance: {chunk_result.importance}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Chunk processing error: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Step 7: Create final metadata using Gemini with Pydantic validation\n",
    "        combined_chunks = \"\\n\\n\".join([f\"Chunk {i+1}: {summary}\" for i, summary in enumerate(chunk_summaries)])\n",
    "        metadata_result = metadata_chain.invoke({\"relevant_chunks\": combined_chunks})\n",
    "        \n",
    "        # Step 8: Structure the final output\n",
    "        \n",
    "        \n",
    "        final_output = {\n",
    "            \"document_info\": {\n",
    "                \"title\": metadata_result.document_info.title,\n",
    "                \"document_type\": metadata_result.document_info.document_type,\n",
    "                \"estimated_pages\": actual_pages,\n",
    "                \"language\": metadata_result.document_info.language,\n",
    "                \"subject_area\": metadata_result.document_info.subject_area\n",
    "            },\n",
    "            \"content_analysis\": {\n",
    "                \"summary\": metadata_result.content_analysis.summary,\n",
    "                \"key_topics\": metadata_result.content_analysis.key_topics,\n",
    "                \"main_entities\": metadata_result.content_analysis.main_entities,\n",
    "                \"themes\": metadata_result.content_analysis.themes\n",
    "            },\n",
    "            \"semantic_tags\": {\n",
    "                \"categories\": metadata_result.semantic_tags.categories,\n",
    "                \"keywords\": metadata_result.semantic_tags.keywords,\n",
    "                \"classification\": metadata_result.semantic_tags.classification\n",
    "            },\n",
    "            \"processing_info\": {\n",
    "                \"total_chunks\": len(chunks),\n",
    "                \"processed_chunks\": len(chunk_summaries),\n",
    "            \n",
    "                \"file_size_kb\": round(os.path.getsize(file_path)/1024, 1)\n",
    "                \n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Clean up temporary ChromaDB\n",
    "        try:\n",
    "            import shutil\n",
    "            shutil.rmtree(persist_dir)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return json.dumps(final_output, indent=2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Error processing document: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39a024d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\metadata_generator\\meta\\Lib\\site-packages\\gradio\\interface.py:419: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Gradio interface\n",
    "interface = gr.Interface(\n",
    "    fn=process_document,\n",
    "    inputs=[\n",
    "        gr.File(\n",
    "            label=\"Upload Document\", \n",
    "            file_types=[\".pdf\", \".docx\", \".txt\", \".png\", \".jpg\", \".jpeg\", \".bmp\", \".tiff\"],\n",
    "            file_count=\"single\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(\n",
    "            label=\"Generated Metadata (JSON)\", \n",
    "            lines=20, \n",
    "            max_lines=30,\n",
    "            show_copy_button=True\n",
    "        )\n",
    "    ],\n",
    "    title=\"🤖 Automated Metadata Generation System\",\n",
    "    description=\"\"\"\n",
    "    Upload any document (PDF, DOCX, TXT, or Image) up to 8MB to automatically generate comprehensive metadata.\n",
    "    \n",
    "    **Features:**\n",
    "    - ✅ Multi-format support (PDF, DOCX, TXT, Images)\n",
    "    - ✅ OCR for image-based documents\n",
    "    - ✅ Semantic content identification\n",
    "    - ✅ Local embedding generation\n",
    "    - ✅ Structured metadata output\n",
    "    - ✅ Document classification and tagging\n",
    "    \n",
    "    **Supported file types:** PDF, DOCX, TXT, PNG, JPG, JPEG, BMP, TIFF\n",
    "    \"\"\",\n",
    "    examples=[],\n",
    "    cache_examples=False,\n",
    "    theme=gr.themes.Soft(),\n",
    "    allow_flagging=\"never\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5697a68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "gr.close_all()  # ⛔ Close any existing Gradio interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "316d0d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\AppData\\Local\\Temp\\ipykernel_7648\\2007394719.py:55: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectorstore.persist()\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    interface.launch(\n",
    "        share=False,\n",
    "        server_name=\"0.0.0.0\",\n",
    "        server_port=7861,\n",
    "        show_error=True,\n",
    "        quiet=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90a5c914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "955bcd60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7861\n"
     ]
    }
   ],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c82265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "meta",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
